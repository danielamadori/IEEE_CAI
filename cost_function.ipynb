{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e6dc64",
   "metadata": {},
   "source": [
    "# testing with ECG"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:46:02.543584Z",
     "start_time": "2025-10-29T16:46:02.198971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train sklearn Random Forest on Iris dataset and save to Redis\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sample_converter import sklearn_sample_to_dict\n",
    "# Import conversion functions\n",
    "from skforest_to_forest import sklearn_forest_to_forest\n",
    "from redis_helpers.forest import store_forest\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.utils import Bunch\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cost_function import cal_sigmas\n",
    "\n",
    "def load_aeon_dataset_padded(dataset_name, return_as_bunch=False, feature_prefix=\"t\"):\n",
    "\tX_train, y_train = load_classification(dataset_name, split=\"train\")\n",
    "\tX_test, y_test = load_classification(dataset_name, split=\"test\")\n",
    "\n",
    "\tprint(f\"Dataset: {dataset_name}\")\n",
    "\tprint(f\"Training set: {X_train.shape} samples\")\n",
    "\tprint(f\"Test set: {X_test.shape} samples\")\n",
    "\tprint(f\"Series length: {X_train.shape[2]} time points\")\n",
    "\tprint(f\"Classes: {np.unique(np.concatenate([y_train, y_test]))}\")\n",
    "\n",
    "\tif return_as_bunch:\n",
    "\t\t# Reshape data: (n_samples, n_channels, n_timepoints) -> (n_samples, n_timepoints)\n",
    "\t\tX_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "\t\tX_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "\t\t# Combine train and test\n",
    "\t\tX_combined = np.vstack([X_train_2d, X_test_2d])\n",
    "\t\ty_combined = np.concatenate([y_train, y_test])\n",
    "\n",
    "\t\t# Calculate padding width based on series length\n",
    "\t\tseries_length = X_combined.shape[1]\n",
    "\t\t# Number of digits needed (e.g., for 2000 points: indices 0-1999, max is 1999 = 4 digits)\n",
    "\t\tpadding_width = len(str(series_length - 1))\n",
    "\n",
    "\t\t# Create zero-padded feature names\n",
    "\t\tfeature_names = [f\"{feature_prefix}_{i:0{padding_width}d}\" for i in range(series_length)]\n",
    "\n",
    "\t\tprint(f\"Feature name format: {padding_width} digits\")\n",
    "\t\tprint(f\"Sample feature names: {feature_names[:5]}...{feature_names[-5:]}\")\n",
    "\n",
    "\t\tbunch = Bunch(\n",
    "\t\t\tdata=X_combined,\n",
    "\t\t\ttarget=y_combined,\n",
    "\t\t\tfeature_names=feature_names,\n",
    "\t\t\ttarget_names=np.unique(y_combined).astype(str),\n",
    "\t\t\tDESCR=f\"Aeon {dataset_name} dataset - univariate time series classification\",\n",
    "\t\t\ttrain_indices=np.arange(len(X_train_2d)),\n",
    "\t\t\ttest_indices=np.arange(len(X_train_2d), len(X_train_2d) + len(X_test_2d)),\n",
    "\t\t\toriginal_shape=X_train.shape[1:],\n",
    "\t\t\tpadding_width=padding_width  # Store for reference\n",
    "\t\t)\n",
    "\t\treturn bunch\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test\n",
    "\n",
    "names_dataset = ['ECG200']\n",
    "dt = {}\n",
    "for name_dataset in names_dataset:\n",
    "\ttmp = load_aeon_dataset_padded(name_dataset, True)\n",
    "\tdt[name_dataset] = {\"X\" : tmp.data, \"y\": tmp.target, \"feature_names\": tmp.feature_names, \"class_names\": tmp.target_names, \"string_labels\" : tmp.target, \"X_train\": tmp.data[tmp.train_indices], \"X_test\": tmp.data[tmp.test_indices], \"y_train\": tmp.target[tmp.train_indices], \"y_test\": tmp.target[tmp.test_indices], \"train_indices\": tmp.train_indices, \"test_indices\": tmp.test_indices}\n",
    "\n",
    "\n",
    "\tprint(f\"Training set: {dt[\"X_train\"].shape[0]} samples\")\n",
    "\tprint(f\"Test set: {dt[\"X_test\"].shape[0]} samples\")\n",
    "\n",
    "\tsigmas_all = cal_sigmas(dt[\"X_train\"], dt[\"X_test\"], dt[\"feature_names\"])\n",
    "\n",
    "\tlist_sample_radis = []\n",
    "\tfor i in range(len(X_test)):\n",
    "\t\tsample= db.get_metadata(i)\n",
    "\t\tlist.append((sample_dict, test_index))\n",
    "\n",
    "\tlista_ar = [ar.bitmpaToICF() for ar in DB ]\n",
    "\tfrom cost_function import cost_function\n",
    "\tpot_rob = {}\n",
    "\tfor (sample_dict, index) in list_sample_radis:\n",
    "\t\tfor icf in lista_ar:\n",
    "\t\t\tc = cost_function(sample_dict, sigmas=sigmas_all, icf=icf, sample_index=index, verbose=True)\n",
    "\t\t\tprint(f\"Sample {index} Cost: {c}\")\n",
    "\n",
    "\t\t\tpot_rob[index] = {'cost': c, 'icf':icf}\n",
    "\t\trobustness = max(pot_rob[index]['cost'])\n",
    "\t\tprint(f\"Overall Robustness: {robustness} for sample {index}\")\n",
    "\tpot_rob.to_csv(f'{name_dataset}_robustness.csv')\n"
   ],
   "id": "d64cc6e136e4eefb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ECG200\n",
      "Training set: (100, 1, 96) samples\n",
      "Test set: (100, 1, 96) samples\n",
      "Series length: 96 time points\n",
      "Classes: ['-1' '1']\n",
      "Feature name format: 2 digits\n",
      "Sample feature names: ['t_00', 't_01', 't_02', 't_03', 't_04']...['t_91', 't_92', 't_93', 't_94', 't_95']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 68\u001B[0m\n\u001B[0;32m     64\u001B[0m tmp \u001B[38;5;241m=\u001B[39m load_aeon_dataset_padded(name_dataset, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     65\u001B[0m dt[name_dataset] \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m : tmp\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtarget, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_names\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mfeature_names, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_names\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtarget_names, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstring_labels\u001B[39m\u001B[38;5;124m\"\u001B[39m : tmp\u001B[38;5;241m.\u001B[39mtarget, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_train\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mdata[tmp\u001B[38;5;241m.\u001B[39mtrain_indices], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_test\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mdata[tmp\u001B[38;5;241m.\u001B[39mtest_indices], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_train\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtarget[tmp\u001B[38;5;241m.\u001B[39mtrain_indices], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_test\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtarget[tmp\u001B[38;5;241m.\u001B[39mtest_indices], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtrain_indices, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m: tmp\u001B[38;5;241m.\u001B[39mtest_indices}\n\u001B[1;32m---> 68\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining set: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mdt\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX_train\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest set: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_test\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     71\u001B[0m sigmas_all \u001B[38;5;241m=\u001B[39m cal_sigmas(dt[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_train\u001B[39m\u001B[38;5;124m\"\u001B[39m], dt[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_test\u001B[39m\u001B[38;5;124m\"\u001B[39m], dt[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_names\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[1;31mKeyError\u001B[0m: 'X_train'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f00150cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:46:02.582162800Z",
     "start_time": "2025-10-29T15:11:09.065893Z"
    }
   },
   "source": "\n",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 9\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcost_function\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cal_sigmas\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mECG dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mX\u001B[49m\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(feature_names)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeatures: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_names\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClasses: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_names\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ecg = load_aeon_dataset_padded('ECG200', True)\n",
    "# Load ecg dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = ecg.data, ecg.target\n",
    "feature_names = ecg.feature_names\n",
    "class_names = ecg.target_names\n",
    "string_labels = ecg.target\n",
    "\n",
    "\n",
    "print(f\"ECG dataset: {X.shape} samples, {len(feature_names)} features\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, string_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "from cost_function import cal_sigmas\n",
    "\n",
    "sigmas_all = cal_sigmas(X_train, X_test, feature_names)\n",
    "\n",
    "list_sample_radis = []\n",
    "for i in range(len(X_test)):\n",
    "\n"
   ],
   "id": "66566d0df521df3d"
  },
  {
   "cell_type": "markdown",
   "id": "e94d7d91",
   "metadata": {},
   "source": [
    "# calc sigmas + and - on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_function import cal_sigmas\n",
    "\n",
    "sigmas_all = cal_sigmas(X_train, X_test, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cda6ea",
   "metadata": {},
   "source": [
    "# Creation of ICF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fdde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "icf = {}\n",
    "for k in feature_names:\n",
    "\tint_sub = random.uniform(-1, 0)\n",
    "\ticf[k] = (int_sub, int_sub*1.2)\n",
    "icf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9da63",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b762f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_function import cost_function\n",
    "\n",
    "cost_function(sample_dict, sigmas=sigmas_all, icf=icf, sample_index=sample_index, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3408f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44757f2d",
   "metadata": {},
   "source": [
    "# plotting for sez 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad577695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ECG200 time series, corridor, and intervals outside\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the first test sample from ECG200\n",
    "sample_idx = 1\n",
    "series = X_test[sample_idx]\n",
    "feature_names_ecg = feature_names\n",
    "n_points_ecg = len(series)\n",
    "x_ecg = np.arange(n_points_ecg)\n",
    "\n",
    "# Plot 1: ECG time series only\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.title('ECG200 Time Series (Test Sample)')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot 2: ECG time series with corridor and intervals outside\n",
    "corridor_width_ecg = 0.3\n",
    "upper_corridor_ecg = series + corridor_width_ecg\n",
    "lower_corridor_ecg = series - corridor_width_ecg\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.fill_between(x_ecg, lower_corridor_ecg, upper_corridor_ecg, color='orange', alpha=0.3, label='Darwiche Reason')\n",
    "\n",
    "# Generate random intervals outside the corridor\n",
    "num_intervals_ecg = 3\n",
    "np.random.seed(123)\n",
    "for i in range(num_intervals_ecg):\n",
    "\tidx_start = np.random.randint(0, n_points_ecg // 2)\n",
    "\tidx_end = idx_start + np.random.randint(5, 15)\n",
    "\tif idx_end >= n_points_ecg:\n",
    "\t\tidx_end = n_points_ecg - 1\n",
    "\tif np.random.rand() > 0.5:\n",
    "\t\ty_base = upper_corridor_ecg[idx_start:idx_end] + np.random.uniform(0.2, 0.5)\n",
    "\telse:\n",
    "\t\ty_base = lower_corridor_ecg[idx_start:idx_end] - np.random.uniform(0.2, 0.5)\n",
    "\tplt.plot(x_ecg[idx_start:idx_end], y_base, color='orange', linewidth=4, alpha=0.3)\n",
    "\n",
    "plt.title('ECG200 Time Series with Darwiche Reason')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3 our maximal reason corridor only\n",
    "np.random.seed(2025)\n",
    "base_width_maximal = 0.3\n",
    "random_offsets_maximal = np.random.uniform(-0.1, 0.1, n_points_ecg)\n",
    "upper_maximal = series + base_width_maximal + random_offsets_maximal\n",
    "lower_maximal = series - base_width_maximal + random_offsets_maximal\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.fill_between(x_ecg, lower_corridor_ecg, upper_corridor_ecg, color='purple', alpha=0.3, label='Maximal Reason')\n",
    "plt.title('ECG200 Time Series with our Maximal Reason')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
