{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e6dc64",
   "metadata": {},
   "source": [
    "# testing with ECG"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train sklearn Random Forest on Iris dataset and save to Redis\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sample_converter import sklearn_sample_to_dict\n",
    "# Import conversion functions\n",
    "from skforest_to_forest import sklearn_forest_to_forest\n",
    "from redis_helpers.forest import store_forest\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.utils import Bunch\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cost_function import cal_sigmas\n",
    "\n",
    "def load_aeon_dataset_padded(dataset_name, return_as_bunch=False, feature_prefix=\"t\"):\n",
    "\tX_train, y_train = load_classification(dataset_name, split=\"train\")\n",
    "\tX_test, y_test = load_classification(dataset_name, split=\"test\")\n",
    "\n",
    "\tprint(f\"Dataset: {dataset_name}\")\n",
    "\tprint(f\"Training set: {X_train.shape} samples\")\n",
    "\tprint(f\"Test set: {X_test.shape} samples\")\n",
    "\tprint(f\"Series length: {X_train.shape[2]} time points\")\n",
    "\tprint(f\"Classes: {np.unique(np.concatenate([y_train, y_test]))}\")\n",
    "\n",
    "\tif return_as_bunch:\n",
    "\t\t# Reshape data: (n_samples, n_channels, n_timepoints) -> (n_samples, n_timepoints)\n",
    "\t\tX_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "\t\tX_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "\t\t# Combine train and test\n",
    "\t\tX_combined = np.vstack([X_train_2d, X_test_2d])\n",
    "\t\ty_combined = np.concatenate([y_train, y_test])\n",
    "\n",
    "\t\t# Calculate padding width based on series length\n",
    "\t\tseries_length = X_combined.shape[1]\n",
    "\t\t# Number of digits needed (e.g., for 2000 points: indices 0-1999, max is 1999 = 4 digits)\n",
    "\t\tpadding_width = len(str(series_length - 1))\n",
    "\n",
    "\t\t# Create zero-padded feature names\n",
    "\t\tfeature_names = [f\"{feature_prefix}_{i:0{padding_width}d}\" for i in range(series_length)]\n",
    "\n",
    "\t\tprint(f\"Feature name format: {padding_width} digits\")\n",
    "\t\tprint(f\"Sample feature names: {feature_names[:5]}...{feature_names[-5:]}\")\n",
    "\n",
    "\t\tbunch = Bunch(\n",
    "\t\t\tdata=X_combined,\n",
    "\t\t\ttarget=y_combined,\n",
    "\t\t\tfeature_names=feature_names,\n",
    "\t\t\ttarget_names=np.unique(y_combined).astype(str),\n",
    "\t\t\tDESCR=f\"Aeon {dataset_name} dataset - univariate time series classification\",\n",
    "\t\t\ttrain_indices=np.arange(len(X_train_2d)),\n",
    "\t\t\ttest_indices=np.arange(len(X_train_2d), len(X_train_2d) + len(X_test_2d)),\n",
    "\t\t\toriginal_shape=X_train.shape[1:],\n",
    "\t\t\tpadding_width=padding_width  # Store for reference\n",
    "\t\t)\n",
    "\t\treturn bunch\n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test\n",
    "\n",
    "names_dataset = ['ECG200']\n",
    "dt = {}\n",
    "for name_dataset in names_dataset:\n",
    "\ttmp = load_aeon_dataset_padded(name_dataset, True)\n",
    "\tdt[name_dataset] = {\"X\" : tmp.data, \"y\": tmp.target, \"feature_names\": tmp.feature_names, \"class_names\": tmp.target_names, \"string_labels\" : tmp.target, \"X_train\": tmp.data[tmp.train_indices], \"X_test\": tmp.data[tmp.test_indices], \"y_train\": tmp.target[tmp.train_indices], \"y_test\": tmp.target[tmp.test_indices], \"train_indices\": tmp.train_indices, \"test_indices\": tmp.test_indices}\n",
    "\n",
    "\n",
    "\tprint(f\"Training set: {dt[\"X_train\"].shape[0]} samples\")\n",
    "\tprint(f\"Test set: {dt[\"X_test\"].shape[0]} samples\")\n",
    "\n",
    "\tsigmas_all = cal_sigmas(dt[\"X_train\"], dt[\"X_test\"], dt[\"feature_names\"])\n",
    "\n",
    "\t'''\n",
    "\tlist_sample_radis = []\n",
    "\tfor i in range(len(X_test)):\n",
    "\t\tsample= db.get_metadata(i)\n",
    "\t\tlist.append((sample_dict, test_index))\n",
    "\n",
    "\tlista_ar = [ar.bitmpaToICF() for ar in DB ]\n",
    "\tfrom cost_function import cost_function\n",
    "\tpot_rob = {}\n",
    "\tfor (sample_dict, index) in list_sample_radis:\n",
    "\t\tfor icf in lista_ar:\n",
    "\t\t\tc = cost_function(sample_dict, sigmas=sigmas_all, icf=icf, sample_index=index, verbose=True)\n",
    "\t\t\tprint(f\"Sample {index} Cost: {c}\")\n",
    "\n",
    "\t\t\tpot_rob[index] = {'cost': c, 'icf':icf}\n",
    "\t\trobustness = max(pot_rob[index]['cost'])\n",
    "\t\tprint(f\"Overall Robustness: {robustness} for sample {index}\")\n",
    "\tpot_rob.to_csv(f'{name_dataset}_robustness.csv')\n",
    "\t'''\n"
   ],
   "id": "d64cc6e136e4eefb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f00150cf",
   "metadata": {},
   "source": "\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ecg = load_aeon_dataset_padded('ECG200', True)\n",
    "# Load ecg dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = ecg.data, ecg.target\n",
    "feature_names = ecg.feature_names\n",
    "class_names = ecg.target_names\n",
    "string_labels = ecg.target\n",
    "\n",
    "\n",
    "print(f\"ECG dataset: {X.shape} samples, {len(feature_names)} features\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, string_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "from cost_function import cal_sigmas\n",
    "\n",
    "sigmas_all = cal_sigmas(X_train, X_test, feature_names)\n",
    "\n",
    "list_sample_radis = []\n",
    "for i in range(len(X_test)):\n",
    "\n"
   ],
   "id": "66566d0df521df3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e94d7d91",
   "metadata": {},
   "source": [
    "# calc sigmas + and - on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "91aeb755",
   "metadata": {},
   "source": [
    "from cost_function import cal_sigmas\n",
    "\n",
    "sigmas_all = cal_sigmas(X_train, X_test, feature_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11cda6ea",
   "metadata": {},
   "source": [
    "# Creation of ICF"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec6fdde1",
   "metadata": {},
   "source": [
    "import random\n",
    "icf = {}\n",
    "for k in feature_names:\n",
    "\tint_sub = random.uniform(-1, 0)\n",
    "\ticf[k] = (int_sub, int_sub*1.2)\n",
    "icf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4a9da63",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "id": "57b762f9",
   "metadata": {},
   "source": [
    "from cost_function import cost_function\n",
    "\n",
    "cost_function(sample_dict, sigmas=sigmas_all, icf=icf, sample_index=sample_index, verbose=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3408f29",
   "metadata": {},
   "source": [
    "len(feature_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44757f2d",
   "metadata": {},
   "source": [
    "# plotting for sez 3"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad577695",
   "metadata": {},
   "source": [
    "# Plot ECG200 time series, corridor, and intervals outside\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the first test sample from ECG200\n",
    "sample_idx = 1\n",
    "series = X_test[sample_idx]\n",
    "feature_names_ecg = feature_names\n",
    "n_points_ecg = len(series)\n",
    "x_ecg = np.arange(n_points_ecg)\n",
    "\n",
    "# Plot 1: ECG time series only\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.title('ECG200 Time Series (Test Sample)')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot 2: ECG time series with corridor and intervals outside\n",
    "corridor_width_ecg = 0.3\n",
    "upper_corridor_ecg = series + corridor_width_ecg\n",
    "lower_corridor_ecg = series - corridor_width_ecg\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.fill_between(x_ecg, lower_corridor_ecg, upper_corridor_ecg, color='orange', alpha=0.3, label='Darwiche Reason')\n",
    "\n",
    "# Generate random intervals outside the corridor\n",
    "num_intervals_ecg = 3\n",
    "np.random.seed(123)\n",
    "for i in range(num_intervals_ecg):\n",
    "\tidx_start = np.random.randint(0, n_points_ecg // 2)\n",
    "\tidx_end = idx_start + np.random.randint(5, 15)\n",
    "\tif idx_end >= n_points_ecg:\n",
    "\t\tidx_end = n_points_ecg - 1\n",
    "\tif np.random.rand() > 0.5:\n",
    "\t\ty_base = upper_corridor_ecg[idx_start:idx_end] + np.random.uniform(0.2, 0.5)\n",
    "\telse:\n",
    "\t\ty_base = lower_corridor_ecg[idx_start:idx_end] - np.random.uniform(0.2, 0.5)\n",
    "\tplt.plot(x_ecg[idx_start:idx_end], y_base, color='orange', linewidth=4, alpha=0.3)\n",
    "\n",
    "plt.title('ECG200 Time Series with Darwiche Reason')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3 our maximal reason corridor only\n",
    "np.random.seed(2025)\n",
    "base_width_maximal = 0.3\n",
    "random_offsets_maximal = np.random.uniform(-0.1, 0.1, n_points_ecg)\n",
    "upper_maximal = series + base_width_maximal + random_offsets_maximal\n",
    "lower_maximal = series - base_width_maximal + random_offsets_maximal\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_ecg, series, label='ECG200 Time Series', color='blue')\n",
    "plt.fill_between(x_ecg, lower_corridor_ecg, upper_corridor_ecg, color='purple', alpha=0.3, label='Maximal Reason')\n",
    "plt.title('ECG200 Time Series with our Maximal Reason')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
